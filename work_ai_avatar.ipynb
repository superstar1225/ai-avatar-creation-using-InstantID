{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a13add04-e8eb-4ca0-bf75-60fce4f6dfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'InstantID'...\n",
      "remote: Enumerating objects: 417, done.\u001b[K\n",
      "remote: Counting objects: 100% (172/172), done.\u001b[K\n",
      "remote: Compressing objects: 100% (111/111), done.\u001b[K\n",
      "remote: Total 417 (delta 123), reused 62 (delta 61), pack-reused 245\u001b[K\n",
      "Receiving objects: 100% (417/417), 146.91 MiB | 29.59 MiB/s, done.\n",
      "Resolving deltas: 100% (226/226), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/InstantID/InstantID.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6a36719-c14a-4afc-8694-6cfdafe52ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.9.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Collecting tqdm (from gdown)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, PySocks, gdown\n",
      "Successfully installed PySocks-1.7.1 gdown-5.1.0 tqdm-4.66.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ec969f-ef8b-4f52-b3f1-59975f530d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288431d9-5ec7-4dd8-9235-0d9344f318e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'models' folder has been created.\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"/workspace\"\n",
    "\n",
    "new_folder_path = os.path.join(directory_path, \"models\")\n",
    "\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.mkdir(new_folder_path)\n",
    "    print(\"The 'models' folder has been created.\")\n",
    "else:\n",
    "    print(\"The 'models' folder already exists in the specified directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ea2054-39b9-4517-9b46-dc1ab864e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://drive.google.com/uc?id=1qXsQJ8ZT42_xSmWIYy85IcidpiZudOCB',\n",
    "    'https://drive.google.com/uc?id=1net68yNxF33NNV6WP7k56FS6V53tq-64',\n",
    "    'https://drive.google.com/uc?id=1pKIusApEfoHKDjeBTXYB3yOQ0EtTonNE',\n",
    "    'https://drive.google.com/uc?id=18wEUfMNohBJ4K3Ly5wpTejPfDzp-8fI8',\n",
    "    'https://drive.google.com/uc?id=19I-MZdctYKmVf3nu5Da3HS6KH5LBfdzG'\n",
    "]\n",
    "\n",
    "# outputs = [\n",
    "#     '/workspace/models/buffalo_l.zip',\n",
    "#     '/workspace/models/buffalo_m.zip',\n",
    "#     '/workspace/models/buffalo_s.zip',\n",
    "#     '/workspace/models/antelopev2.zip',\n",
    "#     '/workspace/models/buffalo_sc.zip'\n",
    "# ]\n",
    "\n",
    "outputs = [\n",
    "    '/models/buffalo_l.zip',\n",
    "    '/models/buffalo_m.zip',\n",
    "    '/models/buffalo_s.zip',\n",
    "    '/models/antelopev2.zip',\n",
    "    '/models/buffalo_sc.zip'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4731c95e-3739-4744-a004-d666282179e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1qXsQJ8ZT42_xSmWIYy85IcidpiZudOCB\n",
      "From (redirected): https://drive.google.com/uc?id=1qXsQJ8ZT42_xSmWIYy85IcidpiZudOCB&confirm=t&uuid=8851dd14-dcad-4d2d-8dd4-6fb3bd4a2e97\n",
      "To: /workspace/models/buffalo_l.zip\n",
      "100%|██████████| 289M/289M [00:03<00:00, 76.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1net68yNxF33NNV6WP7k56FS6V53tq-64\n",
      "From (redirected): https://drive.google.com/uc?id=1net68yNxF33NNV6WP7k56FS6V53tq-64&confirm=t&uuid=240143ca-a396-401c-a47f-a588b40c9c93\n",
      "To: /workspace/models/buffalo_m.zip\n",
      "100%|██████████| 276M/276M [00:05<00:00, 50.5MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1pKIusApEfoHKDjeBTXYB3yOQ0EtTonNE\n",
      "From (redirected): https://drive.google.com/uc?id=1pKIusApEfoHKDjeBTXYB3yOQ0EtTonNE&confirm=t&uuid=62fbb718-7b42-4d2b-9808-2176bf578a76\n",
      "To: /workspace/models/buffalo_s.zip\n",
      "100%|██████████| 128M/128M [00:01<00:00, 82.6MB/s] \n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18wEUfMNohBJ4K3Ly5wpTejPfDzp-8fI8\n",
      "From (redirected): https://drive.google.com/uc?id=18wEUfMNohBJ4K3Ly5wpTejPfDzp-8fI8&confirm=t&uuid=b10e1587-b71b-45fd-b6a8-4d75bc65406f\n",
      "To: /workspace/models/antelopev2.zip\n",
      "100%|██████████| 361M/361M [00:04<00:00, 75.7MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19I-MZdctYKmVf3nu5Da3HS6KH5LBfdzG\n",
      "To: /workspace/models/buffalo_sc.zip\n",
      "100%|██████████| 15.0M/15.0M [00:00<00:00, 36.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(urls)):\n",
    "    gdown.download(urls[i], outputs[i], quiet=False)\n",
    "\n",
    "    # with zipfile.ZipFile(outputs[i], mode='r') as z:\n",
    "    #     z.extractall('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49540d3c-aada-4f60-8cbb-65d94a7773c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/InstantID\n",
      "LICENSE      gradio_cached_examples\n",
      "README.md    gradio_demo\n",
      "__pycache__  infer.py\n",
      "assets\t     infer_full.py\n",
      "checkpoints  ip_adapter\n",
      "cog\t     models\n",
      "cog.yaml     pipeline_stable_diffusion_xl_instantid.py\n",
      "docs\t     pipeline_stable_diffusion_xl_instantid_full.py\n",
      "examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd \"/workspace/InstantID\"\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e43e757c-5486-4313-bdde-0c8bd0ecfe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'models' folder has been created.\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"/workspace/InstantID\"\n",
    "\n",
    "new_folder_path = os.path.join(directory_path, \"models\")\n",
    "\n",
    "if not os.path.exists(new_folder_path):\n",
    "    os.mkdir(new_folder_path)\n",
    "    print(\"The 'models' folder has been created.\")\n",
    "else:\n",
    "    print(\"The 'models' folder already exists in the specified directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08ef54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('models/antelopev2.zip', mode='r') as z:\n",
    "    z.extractall('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2413e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(urls)):\n",
    "    # gdown.download(urls[i], outputs[i], quiet=False)\n",
    "\n",
    "    with zipfile.ZipFile(outputs[i], mode='r') as z:\n",
    "        z.extractall('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6607403a-6da2-4d98-bbfd-5b4b59f0f0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers==0.25.1 (from -r gradio_demo/requirements.txt (line 1))\n",
      "  Downloading diffusers-0.25.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torch==2.0.0 (from -r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.15.1 (from -r gradio_demo/requirements.txt (line 3))\n",
      "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers==4.37.1 (from -r gradio_demo/requirements.txt (line 4))\n",
      "  Downloading transformers-4.37.1-py3-none-any.whl.metadata (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting accelerate (from -r gradio_demo/requirements.txt (line 5))\n",
      "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting safetensors (from -r gradio_demo/requirements.txt (line 6))\n",
      "  Downloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting einops (from -r gradio_demo/requirements.txt (line 7))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting onnxruntime-gpu (from -r gradio_demo/requirements.txt (line 8))\n",
      "  Downloading onnxruntime_gpu-1.17.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting spaces==0.19.4 (from -r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading spaces-0.19.4-py3-none-any.whl.metadata (972 bytes)\n",
      "Collecting omegaconf (from -r gradio_demo/requirements.txt (line 10))\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting peft (from -r gradio_demo/requirements.txt (line 11))\n",
      "  Downloading peft-0.8.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting huggingface-hub==0.20.2 (from -r gradio_demo/requirements.txt (line 12))\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting opencv-python (from -r gradio_demo/requirements.txt (line 13))\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting insightface (from -r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio (from -r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading gradio-4.19.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting controlnet_aux (from -r gradio_demo/requirements.txt (line 16))\n",
      "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gdown (from -r gradio_demo/requirements.txt (line 17))\n",
      "  Downloading gdown-5.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (4.6.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (1.24.1)\n",
      "Collecting regex!=2019.12.17 (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (9.3.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m99.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1->-r gradio_demo/requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.1->-r gradio_demo/requirements.txt (line 4)) (6.0.1)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.1->-r gradio_demo/requirements.txt (line 4))\n",
      "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==4.37.1->-r gradio_demo/requirements.txt (line 4))\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpx>=0.20 (from spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: psutil<6,>=2 in /usr/local/lib/python3.10/dist-packages (from spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (5.9.6)\n",
      "Collecting pydantic<3,>=1 (from spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl.metadata (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub==0.20.2->-r gradio_demo/requirements.txt (line 12))\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (68.2.2)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (0.41.3)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting coloredlogs (from onnxruntime-gpu->-r gradio_demo/requirements.txt (line 8))\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime-gpu->-r gradio_demo/requirements.txt (line 8))\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime-gpu->-r gradio_demo/requirements.txt (line 8))\n",
      "  Downloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r gradio_demo/requirements.txt (line 10))\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting onnx (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Collecting matplotlib (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting scipy (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting scikit-image (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting easydict (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading easydict-1.12-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cython (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Using cached Cython-3.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting albumentations (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting prettytable (from insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading prettytable-3.9.0-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting fastapi (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading fastapi-0.109.2-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting ffmpy (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.10.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading gradio_client-0.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading importlib_resources-6.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r gradio_demo/requirements.txt (line 15)) (2.1.2)\n",
      "Collecting orjson~=3.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading orjson-3.9.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas<3.0,>=1.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pydub (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ruff>=0.1.7 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading ruff-0.2.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (23 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting uvicorn>=0.14.0 (from gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting websockets<12.0,>=10.0 (from gradio-client==0.10.0->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting timm (from controlnet_aux->-r gradio_demo/requirements.txt (line 16))\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->-r gradio_demo/requirements.txt (line 17)) (4.12.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15)) (4.19.2)\n",
      "Collecting toolz (from altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (4.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (2022.12.7)\n",
      "Collecting httpcore==1.* (from httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading httpcore-1.0.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (3.4)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (1.3.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting contourpy>=1.0.1 (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading fonttools-4.48.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.9/158.9 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface->-r gradio_demo/requirements.txt (line 14)) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0,>=1.0->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.2 (from pydantic<3,>=1->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9))\n",
      "  Downloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting typing-extensions (from torch==2.0.0->-r gradio_demo/requirements.txt (line 2))\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.25.1->-r gradio_demo/requirements.txt (line 1)) (1.26.13)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich<14.0.0,>=10.11.0 (from typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading rich-13.7.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting qudida>=0.0.4 (from albumentations->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting imageio>=2.27 (from scikit-image->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading imageio-2.34.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->-r gradio_demo/requirements.txt (line 17)) (2.5)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r gradio_demo/requirements.txt (line 8))\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface->-r gradio_demo/requirements.txt (line 14)) (0.2.9)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown->-r gradio_demo/requirements.txt (line 17))\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn->insightface->-r gradio_demo/requirements.txt (line 14))\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->-r gradio_demo/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15)) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r gradio_demo/requirements.txt (line 15)) (0.12.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->insightface->-r gradio_demo/requirements.txt (line 14)) (1.16.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15)) (2.16.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20->spaces==0.19.4->-r gradio_demo/requirements.txt (line 9)) (1.1.3)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r gradio_demo/requirements.txt (line 15))\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading diffusers-0.25.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading spaces-0.19.4-py3-none-any.whl (15 kB)\n",
      "Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime_gpu-1.17.0-cp310-cp310-manylinux_2_28_x86_64.whl (192.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio-4.19.0-py3-none-any.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-0.10.0-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading gdown-5.1.0-py3-none-any.whl (17 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.2.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached Cython-3.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading easydict-1.12-py3-none-any.whl (6.7 kB)\n",
      "Downloading fastapi-0.109.2-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading scikit_learn-1.4.0-1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (310 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.48.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading imageio-2.34.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.4/313.4 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Downloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime, insightface, controlnet_aux, ffmpy, lit\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=ec534e536b5272933ca529f3fb87d25c53c20abe12e0e945850d28fd6614a01d\n",
      "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
      "  Building wheel for insightface (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1054123 sha256=178b6b21e06dae3cd9c160093d9aa13ebb38adcf877713e8550c5306cf630062\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
      "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274341 sha256=6d8bae43b7de7609666e008d91cfea599b5dd529089440d100c6bc86cd7ec06d\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=b8d854d8d53e5070a144a8291d5cadc53768fdddbe7e17ed7f88c0e1fb76ef7c\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=9376580156d45fd6d5fd1143b163400c98e95af9dbabff78d625506bef2f9a2f\n",
      "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
      "Successfully built antlr4-python3-runtime insightface controlnet_aux ffmpy lit\n",
      "Installing collected packages: pytz, pydub, lit, flatbuffers, ffmpy, easydict, cmake, antlr4-python3-runtime, websockets, tzdata, typing-extensions, tqdm, toolz, tomlkit, tifffile, threadpoolctl, shellingham, semantic-version, scipy, safetensors, ruff, regex, python-multipart, PySocks, protobuf, prettytable, orjson, opencv-python-headless, opencv-python, omegaconf, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, mdurl, lazy_loader, kiwisolver, joblib, importlib-resources, imageio, humanfriendly, h11, fsspec, fonttools, einops, cython, cycler, contourpy, colorama, click, annotated-types, aiofiles, uvicorn, typer, starlette, scikit-learn, scikit-image, pydantic-core, pandas, onnx, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib, markdown-it-py, huggingface-hub, httpcore, coloredlogs, tokenizers, rich, qudida, pydantic, onnxruntime-gpu, httpx, gdown, diffusers, transformers, gradio-client, fastapi, altair, albumentations, insightface, gradio, spaces, triton, torch, torchvision, timm, accelerate, peft, controlnet_aux\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0+cu118\n",
      "    Uninstalling torch-2.1.0+cu118:\n",
      "      Successfully uninstalled torch-2.1.0+cu118\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.0+cu118\n",
      "    Uninstalling torchvision-0.16.0+cu118:\n",
      "      Successfully uninstalled torchvision-0.16.0+cu118\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PySocks-1.7.1 accelerate-0.27.2 aiofiles-23.2.1 albumentations-1.3.1 altair-5.2.0 annotated-types-0.6.0 antlr4-python3-runtime-4.9.3 click-8.1.7 cmake-3.28.3 colorama-0.4.6 coloredlogs-15.0.1 contourpy-1.2.0 controlnet_aux-0.0.7 cycler-0.12.1 cython-3.0.8 diffusers-0.25.1 easydict-1.12 einops-0.7.0 fastapi-0.109.2 ffmpy-0.3.2 flatbuffers-23.5.26 fonttools-4.48.1 fsspec-2024.2.0 gdown-5.1.0 gradio-4.19.0 gradio-client-0.10.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 huggingface-hub-0.20.2 humanfriendly-10.0 imageio-2.34.0 importlib-resources-6.1.1 insightface-0.7.3 joblib-1.3.2 kiwisolver-1.4.5 lazy_loader-0.3 lit-17.0.6 markdown-it-py-3.0.0 matplotlib-3.8.3 mdurl-0.1.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 omegaconf-2.3.0 onnx-1.15.0 onnxruntime-gpu-1.17.0 opencv-python-4.9.0.80 opencv-python-headless-4.9.0.80 orjson-3.9.14 pandas-2.2.0 peft-0.8.2 prettytable-3.9.0 protobuf-4.25.2 pydantic-2.6.1 pydantic-core-2.16.2 pydub-0.25.1 python-multipart-0.0.9 pytz-2024.1 qudida-0.0.4 regex-2023.12.25 rich-13.7.0 ruff-0.2.1 safetensors-0.4.2 scikit-image-0.22.0 scikit-learn-1.4.0 scipy-1.12.0 semantic-version-2.10.0 shellingham-1.5.4 spaces-0.19.4 starlette-0.36.3 threadpoolctl-3.3.0 tifffile-2024.2.12 timm-0.9.12 tokenizers-0.15.2 tomlkit-0.12.0 toolz-0.12.1 torch-2.0.0 torchvision-0.15.1 tqdm-4.66.2 transformers-4.37.1 triton-2.0.0 typer-0.9.0 typing-extensions-4.9.0 tzdata-2024.1 uvicorn-0.27.1 websockets-11.0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r gradio_demo/requirements.txt\n",
    "# !python gradio_demo/download_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e308006d-9c92-4d30-a3ae-555b3fe260cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.24.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (4.25.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.17.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime\n",
      "Successfully installed onnxruntime-1.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8349401a-6e28-4880-9d59-b2994506a766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "2.1.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce755ee2-9acb-426a-8432-0df5f64b2a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Achilles\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "ControlNetModel/config.json: 100%|██████████| 1.38k/1.38k [00:00<?, ?B/s]\n",
      "diffusion_pytorch_model.safetensors:  15%|█▍        | 367M/2.50G [04:49<21:33, 1.65MB/s] Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/e7/87/e787a7a4c89b83529c9661aaedad7af97ed194e375a36d1b2fc30f893aa849f5/c8127be9f174101ebdafee9964d856b49b634435cf6daa396d3f593cf0bbbb05?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27diffusion_pytorch_model.safetensors%3B+filename%3D%22diffusion_pytorch_model.safetensors%22%3B&Expires=1708519376&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODUxOTM3Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2U3Lzg3L2U3ODdhN2E0Yzg5YjgzNTI5Yzk2NjFhYWVkYWQ3YWY5N2VkMTk0ZTM3NWEzNmQxYjJmYzMwZjg5M2FhODQ5ZjUvYzgxMjdiZTlmMTc0MTAxZWJkYWZlZTk5NjRkODU2YjQ5YjYzNDQzNWNmNmRhYTM5NmQzZjU5M2NmMGJiYmIwNT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=HiJh2hhg3668HK7pP1IZ7DuNqrzvuW4WuCxImDANDLp02GJbTraTgLMnrXJQyiuMwHHqAKr0KWFy3m2qMi%7EkVASSU3PjYrQ%7EsCo6hhcgCTv5ckL55NWEVf%7ErmENCmUnAKtxY3VDiBgwk9DcbyD8%7Er1SqyWnoLRLrtnzgOcOcUAzTEfjUPYk9jBzpdQoNJKSj7jfPTu78fhuTlUkzd-4oOOPDU%7E6vUXmkZbvoLMzaWUJAG-L4PmX-w85wTnO3zuWWGBwneMzX2woIO3pH08fboHxc3xleyD32O1fepnNCoDyvmTvcz0s1sF7BOK7V%7EAZuDbD-hmTJAF92-GKSTby3aw__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "diffusion_pytorch_model.safetensors: 100%|██████████| 2.50G/2.50G [18:54<00:00, 1.88MB/s]\n",
      "diffusion_pytorch_model.safetensors:  15%|█▍        | 367M/2.50G [23:52<2:18:56, 256kB/s]\n",
      "ip-adapter.bin:  71%|███████   | 1.20G/1.69G [16:58<06:05, 1.36MB/s]Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/e7/87/e787a7a4c89b83529c9661aaedad7af97ed194e375a36d1b2fc30f893aa849f5/02b3618e36d803784166660520098089a81388e61a93ef8002aa79a5b1c546e1?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27ip-adapter.bin%3B+filename%3D%22ip-adapter.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1708520859&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwODUyMDg1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2U3Lzg3L2U3ODdhN2E0Yzg5YjgzNTI5Yzk2NjFhYWVkYWQ3YWY5N2VkMTk0ZTM3NWEzNmQxYjJmYzMwZjg5M2FhODQ5ZjUvMDJiMzYxOGUzNmQ4MDM3ODQxNjY2NjA1MjAwOTgwODlhODEzODhlNjFhOTNlZjgwMDJhYTc5YTViMWM1NDZlMT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=g6aYffPYV%7ErywUaSBny5fPSSp7v-aqtxoTRsZEKAMaE70BrHwnx8ttFvi6zGo3Pd6UTfVWLx8S2eSkSXZ51XKiAUDhbArJKb8avWaMPPCcgHQnUel%7Ec5AD0tfpjDr7Jg9VwTX6TSMuHpLHjGWXu4st1iuNuc2IZuCHdtO0AgRs5rVxIVSqLQzA-7fD0-9GTixsQKvNlaSanImnoJCS3uORlvtPQUa1LUsL6EDPmmMG7svrgcgaOWnlW%7E8xU%7EA5FM5YVtYRu2XZ2VJ9gTXr3xr0wF0bIu%7EBHfhklF2TXPck5HzzzhXP965OaWYxar-Ar1oxQYPiW7Sd5X21R1%7EF-k3A__&Key-Pair-Id=KCD77M1F0VK2B: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "ip-adapter.bin: 100%|██████████| 1.69G/1.69G [05:26<00:00, 1.52MB/s]\n",
      "ip-adapter.bin:  71%|███████   | 1.20G/1.69G [22:30<09:20, 885kB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./checkpoints\\\\ip-adapter.bin'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id=\"InstantX/InstantID\", filename=\"ControlNetModel/config.json\", local_dir=\"./checkpoints\")\n",
    "hf_hub_download(repo_id=\"InstantX/InstantID\", filename=\"ControlNetModel/diffusion_pytorch_model.safetensors\", local_dir=\"./checkpoints\")\n",
    "hf_hub_download(repo_id=\"InstantX/InstantID\", filename=\"ip-adapter.bin\", local_dir=\"./checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bff92ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python transformers accelerate insightface\n",
    "import diffusers\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.models import ControlNetModel\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from insightface.app import FaceAnalysis\n",
    "from pipeline_stable_diffusion_xl_instantid import StableDiffusionXLInstantIDPipeline, draw_kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d49eb5-f0d4-40ac-a813-2ffc35983004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "# prepare 'antelopev2' under ./models\n",
    "app = FaceAnalysis(name='antelopev2', root='./', providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35db09ee-d896-46ae-9cf8-05273affe969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab08c923afb74352b8c8430d145dec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/800 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f82f2e2f14422d80455e8973979e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36269ff9a61e470ba5e53bf79040cd5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e266eedcb894635bcdc4a5010fc5bc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057132b6f5fc44ceb54dfeef46ad8210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/676 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31bc262c2b41c4a6e1bd67c5ad47e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ce973c6cd340a49107deceb89ed4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229367bda44a44e396357539195a8141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder_2/config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e096635a425847beaa041fe46b0bb711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/737 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a508225df24c2a8729ab0b076a3f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384dd95b89d64107bec3be535b70a0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0446098934c14de4a7e7c9ae5f8f97c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1606e94d612c4093b9a1ab5022c5e9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_2/tokenizer_config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024167cb00004bdcbe15f7d6ad0b2fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/709 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b75cf7fb4c44d868b9432fdb6c9aa3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35931b12d9e4742b991a3ca10b70a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/5.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a1981259684303a21f54b4689c4f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe4a39d3b79461ca335c03804caaf49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare models under ./checkpoints\n",
    "face_adapter = f'./checkpoints/ip-adapter.bin'\n",
    "controlnet_path = f'./checkpoints/ControlNetModel'\n",
    "\n",
    "# load IdentityNet\n",
    "controlnet = ControlNetModel.from_pretrained(controlnet_path, torch_dtype=torch.float16)\n",
    "\n",
    "base_model = 'wangqixun/YamerMIX_v8'  # from https://civitai.com/models/84040?modelVersionId=196039\n",
    "pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n",
    "    base_model,\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "pipe.cuda()\n",
    "\n",
    "# load adapter\n",
    "pipe.load_ip_adapter_instantid(face_adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a458cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c7e2037d1f45a1a39d77f394b017e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load an image\n",
    "face_image = load_image(\"./examples/yann.jpg\")\n",
    "\n",
    "# prepare face emb\n",
    "face_info = app.get(cv2.cvtColor(np.array(face_image), cv2.COLOR_RGB2BGR))\n",
    "face_info = sorted(face_info, key=lambda x:(x['bbox'][2]-x['bbox'][0])*x['bbox'][3]-x['bbox'][1])[-1]  # only use the maximum face\n",
    "face_emb = face_info['embedding']\n",
    "face_kps = draw_kps(face_image, face_info['kps'])\n",
    "\n",
    "# prompt\n",
    "prompt = \"film noir style, ink sketch|vector, male man, highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\"\n",
    "negative_prompt = \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n",
    "\n",
    "# generate image\n",
    "image = pipe(\n",
    "    prompt,\n",
    "    image_embeds=face_emb,\n",
    "    image=face_kps,\n",
    "    controlnet_conditioning_scale=0.8,\n",
    "    ip_adapter_scale=0.8,\n",
    ").images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea073395",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4776ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf1452c578444b99e94e91525f1c479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_lora_weights.safetensors:   0%|          | 0.00/394M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./checkpoints/pytorch_lora_weights.safetensors'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "hf_hub_download(repo_id=\"latent-consistency/lcm-lora-sdxl\", filename=\"pytorch_lora_weights.safetensors\", local_dir=\"./checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861d7286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'skip_prk_steps': True} were passed to LCMScheduler, but are not expected and will be ignored. Please verify your scheduler_config.json configuration file.\n"
     ]
    }
   ],
   "source": [
    "from diffusers import LCMScheduler\n",
    "\n",
    "lcm_lora_path = \"./checkpoints/pytorch_lora_weights.safetensors\"\n",
    "\n",
    "pipe.load_lora_weights(lcm_lora_path)\n",
    "pipe.fuse_lora()\n",
    "pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "num_inference_steps = 10\n",
    "guidance_scale = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef5452f-8069-4363-8c2a-c937b13d6e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20cc2b8a-1211-450e-bc21-6dd67452c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_list = [\n",
    "    {\n",
    "        \"name\": \"(No style)\",\n",
    "        \"prompt\": \"{prompt}\",\n",
    "        \"negative_prompt\": \"\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Watercolor\",\n",
    "        \"prompt\": \"watercolor painting, {prompt}. vibrant, beautiful, painterly, detailed, textural, artistic\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Film Noir\",\n",
    "        \"prompt\": \"film noir style, ink sketch|vector, {prompt} highly detailed, sharp focus, ultra sharpness, monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Neon\",\n",
    "        \"prompt\": \"masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, {prompt}, emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Jungle\",\n",
    "        \"prompt\": 'waist-up \"{prompt} in a Jungle\" by Syd Mead, tangerine cold color palette, muted colors, detailed, 8k,photo r3al,dripping paint,3d toon style,3d style,Movie Still',\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mars\",\n",
    "        \"prompt\": \"{prompt}, Post-apocalyptic. Mars Colony, Scavengers roam the wastelands searching for valuable resources, rovers, bright morning sunlight shining, (detailed) (intricate) (8k) (HDR) (cinematic lighting) (sharp focus)\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Vibrant Color\",\n",
    "        \"prompt\": \"vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, {prompt}, highly detailed, sharp focus, the clouds,colorful,ultra sharpness\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Snow\",\n",
    "        \"prompt\": \"cinema 4d render, {prompt}, high contrast, vibrant and saturated, sico style, surrounded by magical glow,floating ice shards, snow crystals, cold, windy background, frozen natural landscape in background  cinematic atmosphere,highly detailed, sharp focus, intricate design, 3d, unreal engine, octane render, CG best quality, highres, photorealistic, dramatic lighting, artstation, concept art, cinematic, epic Steven Spielberg movie still, sharp focus, smoke, sparks, art by pascal blanche and greg rutkowski and repin, trending on artstation, hyperrealism painting, matte painting, 4k resolution\",\n",
    "        \"negative_prompt\": \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Line art\",\n",
    "        \"prompt\": \"line art drawing {prompt} . professional, sleek, modern, minimalist, graphic, line art, vector graphics\",\n",
    "        \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic\",\n",
    "    },\n",
    "{\n",
    "    \"name\": \"base\",\n",
    "    \"prompt\": \"{prompt}\",\n",
    "    \"negative_prompt\": \"\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"3D Model\",\n",
    "    \"prompt\": \"professional 3d model {prompt} . octane render, highly detailed, volumetric, dramatic lighting\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, low poly, blurry, painting\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Analog Film\",\n",
    "    \"prompt\": \"analog film photo {prompt} . faded film, desaturated, 35mm photo, grainy, vignette, vintage, Kodachrome, Lomography, stained, highly detailed, found footage\",\n",
    "    \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Anime\",\n",
    "    \"prompt\": \"anime artwork {prompt} . anime style, key visual, vibrant, studio anime,  highly detailed\",\n",
    "    \"negative_prompt\": \"photo, deformed, black and white, realism, disfigured, low contrast\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Cinematic\",\n",
    "    \"prompt\": \"cinematic film still {prompt} . shallow depth of field, vignette, highly detailed, high budget, bokeh, cinemascope, moody, epic, gorgeous, film grain, grainy\",\n",
    "    \"negative_prompt\": \"anime, cartoon, graphic, text, painting, crayon, graphite, abstract, glitch, deformed, mutated, ugly, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Comic Book\",\n",
    "    \"prompt\": \"comic {prompt} . graphic illustration, comic art, graphic novel art, vibrant, highly detailed\",\n",
    "    \"negative_prompt\": \"photograph, deformed, glitch, noisy, realistic, stock photo\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Craft Clay\",\n",
    "    \"prompt\": \"play-doh style {prompt} . sculpture, clay art, centered composition, Claymation\",\n",
    "    \"negative_prompt\": \"sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Digital Art\",\n",
    "    \"prompt\": \"concept art {prompt} . digital artwork, illustrative, painterly, matte painting, highly detailed\",\n",
    "    \"negative_prompt\": \"photo, photorealistic, realism, ugly\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Enhance\",\n",
    "    \"prompt\": \"breathtaking {prompt} . award-winning, professional, highly detailed\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, distorted, grainy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Fantasy Art\",\n",
    "    \"prompt\": \"ethereal fantasy concept art of  {prompt} . magnificent, celestial, ethereal, painterly, epic, majestic, magical, fantasy art, cover art, dreamy\",\n",
    "    \"negative_prompt\": \"photographic, realistic, realism, 35mm film, dslr, cropped, frame, text, deformed, glitch, noise, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, sloppy, duplicate, mutated, black and white\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Isometric Style\",\n",
    "    \"prompt\": \"isometric style {prompt} . vibrant, beautiful, crisp, detailed, ultra detailed, intricate\",\n",
    "    \"negative_prompt\": \"deformed, mutated, ugly, disfigured, blur, blurry, noise, noisy, realistic, photographic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Line Art\",\n",
    "    \"prompt\": \"line art drawing {prompt} . professional, sleek, modern, minimalist, graphic, line art, vector graphics\",\n",
    "    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, blurry, noisy, off-center, deformed, cross-eyed, closed eyes, bad anatomy, ugly, disfigured, mutated, realism, realistic, impressionism, expressionism, oil, acrylic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Lowpoly\",\n",
    "    \"prompt\": \"low-poly style {prompt} . low-poly game art, polygon mesh, jagged, blocky, wireframe edges, centered composition\",\n",
    "    \"negative_prompt\": \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Neon Punk\",\n",
    "    \"prompt\": \"neonpunk style {prompt} . cyberpunk, vaporwave, neon, vibes, vibrant, stunningly beautiful, crisp, detailed, sleek, ultramodern, magenta highlights, dark purple shadows, high contrast, cinematic, ultra detailed, intricate, professional\",\n",
    "    \"negative_prompt\": \"painting, drawing, illustration, glitch, deformed, mutated, cross-eyed, ugly, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Origami\",\n",
    "    \"prompt\": \"origami style {prompt} . paper art, pleated paper, folded, origami art, pleats, cut and fold, centered composition\",\n",
    "    \"negative_prompt\": \"noisy, sloppy, messy, grainy, highly detailed, ultra textured, photo\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Photographic\",\n",
    "    \"prompt\": \"cinematic photo {prompt} . 35mm photograph, film, bokeh, professional, 4k, highly detailed\",\n",
    "    \"negative_prompt\": \"drawing, painting, crayon, sketch, graphite, impressionist, noisy, blurry, soft, deformed, ugly\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Pixel Art\",\n",
    "    \"prompt\": \"pixel-art {prompt} . low-res, blocky, pixel art style, 8-bit graphics\",\n",
    "    \"negative_prompt\": \"sloppy, messy, blurry, noisy, highly detailed, ultra textured, photo, realistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Texture\",\n",
    "    \"prompt\": \"texture {prompt} top down close-up\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Advertising\",\n",
    "    \"prompt\": \"Advertising poster style {prompt} . Professional, modern, product-focused, commercial, eye-catching, highly detailed\",\n",
    "    \"negative_prompt\": \"noisy, blurry, amateurish, sloppy, unattractive\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Food Photography\",\n",
    "    \"prompt\": \"Food photography style {prompt} . Appetizing, professional, culinary, high-resolution, commercial, highly detailed\",\n",
    "    \"negative_prompt\": \"unappetizing, sloppy, unprofessional, noisy, blurry\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Real Estate\",\n",
    "    \"prompt\": \"Real estate photography style {prompt} . Professional, inviting, well-lit, high-resolution, property-focused, commercial, highly detailed\",\n",
    "    \"negative_prompt\": \"dark, blurry, unappealing, noisy, unprofessional\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Abstract\",\n",
    "    \"prompt\": \"Abstract style {prompt} . Non-representational, colors and shapes, expression of feelings, imaginative, highly detailed\",\n",
    "    \"negative_prompt\": \"realistic, photographic, figurative, concrete\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Cubist\",\n",
    "    \"prompt\": \"Cubist artwork {prompt} . Geometric shapes, abstract, innovative, revolutionary\",\n",
    "    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Graffiti\",\n",
    "    \"prompt\": \"Graffiti style {prompt} . Street art, vibrant, urban, detailed, tag, mural\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Hyperrealism\",\n",
    "    \"prompt\": \"Hyperrealistic art {prompt} . Extremely high-resolution details, photographic, realism pushed to extreme, fine texture, incredibly lifelike\",\n",
    "    \"negative_prompt\": \"simplified, abstract, unrealistic, impressionistic, low resolution\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Impressionist\",\n",
    "    \"prompt\": \"Impressionist painting {prompt} . Loose brushwork, vibrant color, light and shadow play, captures feeling over form\",\n",
    "    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Pointillism\",\n",
    "    \"prompt\": \"Pointillism style {prompt} . Composed entirely of small, distinct dots of color, vibrant, highly detailed\",\n",
    "    \"negative_prompt\": \"line drawing, smooth shading, large color fields, simplistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Pop Art\",\n",
    "    \"prompt\": \"Pop Art style {prompt} . Bright colors, bold outlines, popular culture themes, ironic or kitsch\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, minimalist\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Psychedelic\",\n",
    "    \"prompt\": \"Psychedelic style {prompt} . Vibrant colors, swirling patterns, abstract forms, surreal, trippy\",\n",
    "    \"negative_prompt\": \"monochrome, black and white, low contrast, realistic, photorealistic, plain, simple\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Renaissance\",\n",
    "    \"prompt\": \"Renaissance style {prompt} . Realistic, perspective, light and shadow, religious or mythological themes, highly detailed\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, modernist, minimalist, abstract\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Steampunk\",\n",
    "    \"prompt\": \"Steampunk style {prompt} . Antique, mechanical, brass and copper tones, gears, intricate, detailed\",\n",
    "    \"negative_prompt\": \"deformed, glitch, noisy, low contrast, anime, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Surrealist\",\n",
    "    \"prompt\": \"Surrealist art {prompt} . Dreamlike, mysterious, provocative, symbolic, intricate, detailed\",\n",
    "    \"negative_prompt\": \"anime, photorealistic, realistic, deformed, glitch, noisy, low contrast\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Typography\",\n",
    "    \"prompt\": \"Typographic art {prompt} . Stylized, intricate, detailed, artistic, text-based\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Watercolor\",\n",
    "    \"prompt\": \"Watercolor painting {prompt} . Vibrant, beautiful, painterly, detailed, textural, artistic\",\n",
    "    \"negative_prompt\": \"anime, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Fighting Game\",\n",
    "    \"prompt\": \"Fighting game style {prompt} . Dynamic, vibrant, action-packed, detailed character design, reminiscent of fighting video games\",\n",
    "    \"negative_prompt\": \"peaceful, calm, minimalist, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"GTA\",\n",
    "    \"prompt\": \"GTA-style artwork {prompt} . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed\",\n",
    "    \"negative_prompt\": \"realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Super Mario\",\n",
    "    \"prompt\": \"Super Mario style {prompt} . Vibrant, cute, cartoony, fantasy, playful, reminiscent of Super Mario series\",\n",
    "    \"negative_prompt\": \"realistic, modern, horror, dystopian, violent\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Minecraft\",\n",
    "    \"prompt\": \"Minecraft style {prompt} . Blocky, pixelated, vibrant colors, recognizable characters and objects, game assets\",\n",
    "    \"negative_prompt\": \"smooth, realistic, detailed, photorealistic, noise, blurry, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Pokémon\",\n",
    "    \"prompt\": \"Pokémon style {prompt} . Vibrant, cute, anime, fantasy, reminiscent of Pokémon series\",\n",
    "    \"negative_prompt\": \"realistic, modern, horror, dystopian, violent\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Retro Arcade\",\n",
    "    \"prompt\": \"Retro arcade style {prompt} . 8-bit, pixelated, vibrant, classic video game, old school gaming, reminiscent of 80s and 90s arcade games\",\n",
    "    \"negative_prompt\": \"modern, ultra-high resolution, photorealistic, 3D\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Retro Game\",\n",
    "    \"prompt\": \"Retro game art {prompt} . 16-bit, vibrant colors, pixelated, nostalgic, charming, fun\",\n",
    "    \"negative_prompt\": \"realistic, photorealistic, 35mm film, deformed, glitch, low contrast, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"RPG Fantasy Game\",\n",
    "    \"prompt\": \"Role-playing game (RPG) style fantasy {prompt} . Detailed, vibrant, immersive, reminiscent of high fantasy RPG games\",\n",
    "    \"negative_prompt\": \"sci-fi, modern, urban, futuristic, low detailed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Strategy Game\",\n",
    "    \"prompt\": \"Strategy game style {prompt} . Overhead view, detailed map, units, reminiscent of real-time strategy video games\",\n",
    "    \"negative_prompt\": \"first-person view, modern, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Street Fighter\",\n",
    "    \"prompt\": \"Street Fighter style {prompt} . Vibrant, dynamic, arcade, 2D fighting game, highly detailed, reminiscent of Street Fighter series\",\n",
    "    \"negative_prompt\": \"3D, realistic, modern, photorealistic, turn-based strategy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Legend of Zelda\",\n",
    "    \"prompt\": \"Legend of Zelda style {prompt} . Vibrant, fantasy, detailed, epic, heroic, reminiscent of The Legend of Zelda series\",\n",
    "    \"negative_prompt\": \"sci-fi, modern, realistic, horror\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Architectural\",\n",
    "    \"prompt\": \"Architectural style {prompt} . Clean lines, geometric shapes, minimalist, modern, architectural drawing, highly detailed\",\n",
    "    \"negative_prompt\": \"curved lines, ornate, baroque, abstract, grunge\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Disco\",\n",
    "    \"prompt\": \"Disco-themed {prompt} . Vibrant, groovy, retro 70s style, shiny disco balls, neon lights, dance floor, highly detailed\",\n",
    "    \"negative_prompt\": \"minimalist, rustic, monochrome, contemporary, simplistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Dreamscape\",\n",
    "    \"prompt\": \"Dreamscape {prompt} . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed\",\n",
    "    \"negative_prompt\": \"realistic, concrete, ordinary, mundane\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Dystopian\",\n",
    "    \"prompt\": \"Dystopian style {prompt} . Bleak, post-apocalyptic, somber, dramatic, highly detailed\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, cheerful, optimistic, vibrant, colorful\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Fairy Tale\",\n",
    "    \"prompt\": \"Fairy tale {prompt} . Magical, fantastical, enchanting, storybook style, highly detailed\",\n",
    "    \"negative_prompt\": \"realistic, modern, ordinary, mundane\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Gothic\",\n",
    "    \"prompt\": \"Gothic style {prompt} . Dark, mysterious, haunting, dramatic, ornate, detailed\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, cheerful, optimistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Grunge\",\n",
    "    \"prompt\": \"Grunge style {prompt} . Textured, distressed, vintage, edgy, punk rock vibe, dirty, noisy\",\n",
    "    \"negative_prompt\": \"smooth, clean, minimalist, sleek, modern, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Horror\",\n",
    "    \"prompt\": \"Horror-themed {prompt} . Eerie, unsettling, dark, spooky, suspenseful, grim, highly detailed\",\n",
    "    \"negative_prompt\": \"cheerful, bright, vibrant, light-hearted, cute\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Minimalist\",\n",
    "    \"prompt\": \"Minimalist style {prompt} . Simple, clean, uncluttered, modern, elegant\",\n",
    "    \"negative_prompt\": \"ornate, complicated, highly detailed, cluttered, disordered, messy, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Monochrome\",\n",
    "    \"prompt\": \"Monochrome {prompt} . Black and white, contrast, tone, texture, detailed\",\n",
    "    \"negative_prompt\": \"colorful, vibrant, noisy, blurry, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Nautical\",\n",
    "    \"prompt\": \"Nautical-themed {prompt} . Sea, ocean, ships, maritime, beach, marine life, highly detailed\",\n",
    "    \"negative_prompt\": \"landlocked, desert, mountains, urban, rustic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Space\",\n",
    "    \"prompt\": \"Space-themed {prompt} . Cosmic, celestial, stars, galaxies, nebulas, planets, science fiction, highly detailed\",\n",
    "    \"negative_prompt\": \"earthly, mundane, ground-based, realism\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Stained Glass\",\n",
    "    \"prompt\": \"Stained glass style {prompt} . Vibrant, beautiful, translucent, intricate, detailed\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Techwear Fashion\",\n",
    "    \"prompt\": \"Techwear fashion {prompt} . Futuristic, cyberpunk, urban, tactical, sleek, dark, highly detailed\",\n",
    "    \"negative_prompt\": \"vintage, rural, colorful, low contrast, realism, sketch, watercolor\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Tribal\",\n",
    "    \"prompt\": \"Tribal style {prompt} . Indigenous, ethnic, traditional patterns, bold, natural colors, highly detailed\",\n",
    "    \"negative_prompt\": \"modern, futuristic, minimalist, pastel\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Zentangle\",\n",
    "    \"prompt\": \"Zentangle {prompt} . Intricate, abstract, monochrome, patterns, meditative, highly detailed\",\n",
    "    \"negative_prompt\": \"colorful, representative, simplistic, large fields of color\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Collage\",\n",
    "    \"prompt\": \"Collage style {prompt} . Mixed media, layered, textural, detailed, artistic\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Flat Papercut\",\n",
    "    \"prompt\": \"Flat papercut style {prompt} . Silhouette, clean cuts, paper, sharp edges, minimalist, color block\",\n",
    "    \"negative_prompt\": \"3D, high detail, noise, grainy, blurry, painting, drawing, photo, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Kirigami\",\n",
    "    \"prompt\": \"Kirigami representation of {prompt} . 3D, paper folding, paper cutting, Japanese, intricate, symmetrical, precision, clean lines\",\n",
    "    \"negative_prompt\": \"painting, drawing, 2D, noisy, blurry, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Paper Mache\",\n",
    "    \"prompt\": \"Paper mache representation of {prompt} . 3D, sculptural, textured, handmade, vibrant, fun\",\n",
    "    \"negative_prompt\": \"2D, flat, photo, sketch, digital art, deformed, noisy, blurry\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Paper Quilling\",\n",
    "    \"prompt\": \"Paper quilling art of {prompt} . Intricate, delicate, curling, rolling, shaping, coiling, loops, 3D, dimensional, ornamental\",\n",
    "    \"negative_prompt\": \"photo, painting, drawing, 2D, flat, deformed, noisy, blurry\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Papercut Collage\",\n",
    "    \"prompt\": \"Papercut collage of {prompt} . Mixed media, textured paper, overlapping, asymmetrical, abstract, vibrant\",\n",
    "    \"negative_prompt\": \"photo, 3D, realistic, drawing, painting, high detail, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Papercut Shadow Box\",\n",
    "    \"prompt\": \"3D papercut shadow box of {prompt} . Layered, dimensional, depth, silhouette, shadow, papercut, handmade, high contrast\",\n",
    "    \"negative_prompt\": \"painting, drawing, photo, 2D, flat, high detail, blurry, noisy, disfigured\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Stacked Papercut\",\n",
    "    \"prompt\": \"Stacked papercut art of {prompt} . 3D, layered, dimensional, depth, precision cut, stacked layers, papercut, high contrast\",\n",
    "    \"negative_prompt\": \"2D, flat, noisy, blurry, painting, drawing, photo, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Thick Layered Papercut\",\n",
    "    \"prompt\": \"Thick layered papercut art of {prompt} . Deep 3D, volumetric, dimensional, depth, thick paper, high stack, heavy texture, tangible layers\",\n",
    "    \"negative_prompt\": \"2D, flat, thin paper, low stack, smooth texture, painting, drawing, photo, deformed\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Alien\",\n",
    "    \"prompt\": \"Alien-themed {prompt} . Extraterrestrial, cosmic, otherworldly, mysterious, sci-fi, highly detailed\",\n",
    "    \"negative_prompt\": \"earthly, mundane, common, realistic, simple\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Film Noir\",\n",
    "    \"prompt\": \"Film noir style {prompt} . Monochrome, high contrast, dramatic shadows, 1940s style, mysterious, cinematic\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, realism, photorealistic, vibrant, colorful\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"HDR\",\n",
    "    \"prompt\": \"HDR photo of {prompt} . High dynamic range, vivid, rich details, clear shadows and highlights, realistic, intense, enhanced contrast, highly detailed\",\n",
    "    \"negative_prompt\": \"flat, low contrast, oversaturated, underexposed, overexposed, blurred, noisy\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Long Exposure\",\n",
    "    \"prompt\": \"Long exposure photo of {prompt} . Blurred motion, streaks of light, surreal, dreamy, ghosting effect, highly detailed\",\n",
    "    \"negative_prompt\": \"static, noisy, deformed, shaky, abrupt, flat, low contrast\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Neon Noir\",\n",
    "    \"prompt\": \"Neon noir {prompt} . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed\",\n",
    "    \"negative_prompt\": \"bright, sunny, daytime, low contrast, black and white, sketch, watercolor\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Silhouette\",\n",
    "    \"prompt\": \"Silhouette style {prompt} . High contrast, minimalistic, black and white, stark, dramatic\",\n",
    "    \"negative_prompt\": \"ugly, deformed, noisy, blurry, low contrast, color, realism, photorealistic\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Tilt-Shift\",\n",
    "    \"prompt\": \"Tilt-shift photo of {prompt} . Selective focus, miniature effect, blurred background, highly detailed, vibrant, perspective control\",\n",
    "    \"negative_prompt\": \"blurry, noisy, deformed, flat, low contrast, unrealistic, oversaturated, underexposed\"\n",
    "  }\n",
    "]\n",
    "\n",
    "styles = {k[\"name\"]: (k[\"prompt\"], k[\"negative_prompt\"]) for k in style_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88ba7f46-821c-40da-a443-3a022ea92283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import diffusers\n",
    "from diffusers.utils import load_image\n",
    "from diffusers.models import ControlNetModel\n",
    "from diffusers import LCMScheduler\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "\n",
    "from diffusers.pipelines.controlnet.multicontrolnet import MultiControlNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09d2f9d4-9e39-4aff-a1c3-ee32364b7c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_stable_diffusion_xl_instantid_full import StableDiffusionXLInstantIDPipeline\n",
    "from gradio_demo.model_util import load_models_xl, get_torch_device, torch_gc\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a472d9d-449c-48c3-ba71-636ce9a18119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c2f467c8e545f2a8be16ddb94c05bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/9.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cf297a377248fea85f5b421949aa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/490M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42ea0a66069470e9ff018068663d373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/382 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3eb93f6377473ca1a1d08dcc5d1b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "body_pose_model.pth:   0%|          | 0.00/209M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from controlnet_aux import OpenposeDetector\n",
    "from gradio_demo.model_util import get_torch_device\n",
    "import cv2\n",
    "\n",
    "\n",
    "from transformers import DPTImageProcessor, DPTForDepthEstimation\n",
    "\n",
    "device = get_torch_device()\n",
    "depth_estimator = DPTForDepthEstimation.from_pretrained(\"Intel/dpt-hybrid-midas\").to(device)\n",
    "feature_extractor = DPTImageProcessor.from_pretrained(\"Intel/dpt-hybrid-midas\")\n",
    "openpose = OpenposeDetector.from_pretrained(\"lllyasviel/ControlNet\")\n",
    "\n",
    "def get_depth_map(image):\n",
    "    image = feature_extractor(images=image, return_tensors=\"pt\").pixel_values.to(\"cuda\")\n",
    "    with torch.no_grad(), torch.autocast(\"cuda\"):\n",
    "        depth_map = depth_estimator(image).predicted_depth\n",
    "\n",
    "    depth_map = torch.nn.functional.interpolate(\n",
    "        depth_map.unsqueeze(1),\n",
    "        size=(1024, 1024),\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    )\n",
    "    depth_min = torch.amin(depth_map, dim=[1, 2, 3], keepdim=True)\n",
    "    depth_max = torch.amax(depth_map, dim=[1, 2, 3], keepdim=True)\n",
    "    depth_map = (depth_map - depth_min) / (depth_max - depth_min)\n",
    "    image = torch.cat([depth_map] * 3, dim=1)\n",
    "\n",
    "    image = image.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
    "    image = Image.fromarray((image * 255.0).clip(0, 255).astype(np.uint8))\n",
    "    return image\n",
    "\n",
    "def get_canny_image(image, t1=100, t2=200):\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    edges = cv2.Canny(image, t1, t2)\n",
    "    return Image.fromarray(edges, \"L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4d0e91c-db91-4e0d-aa7e-d90c0af7d803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faab134d6e14e6aa04971c923699a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d5cbfc6a26747cc9e783afae886fd05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a16d0a0ef5c4b88838f2a5e78449f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03edbeab1824cb486641894f18f83ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/640M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# global variable\n",
    "MAX_SEED = np.iinfo(np.int32).max\n",
    "device = get_torch_device()\n",
    "dtype = torch.float16 if str(device).__contains__(\"cuda\") else torch.float32\n",
    "STYLE_NAMES = list(styles.keys())\n",
    "DEFAULT_STYLE_NAME = \"Watercolor\"\n",
    "\n",
    "# Load face encoder\n",
    "app = FaceAnalysis(\n",
    "    name=\"antelopev2\",\n",
    "    root=\"./\",\n",
    "    providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"],\n",
    ")\n",
    "app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Path to InstantID models\n",
    "face_adapter = f\"./checkpoints/ip-adapter.bin\"\n",
    "controlnet_path = f\"./checkpoints/ControlNetModel\"\n",
    "\n",
    "# Load pipeline face ControlNetModel\n",
    "controlnet_identitynet = ControlNetModel.from_pretrained(\n",
    "    controlnet_path, torch_dtype=dtype\n",
    ")\n",
    "\n",
    "# controlnet-pose\n",
    "controlnet_pose_model = \"thibaud/controlnet-openpose-sdxl-1.0\"\n",
    "controlnet_canny_model = \"diffusers/controlnet-canny-sdxl-1.0\"\n",
    "controlnet_depth_model = \"diffusers/controlnet-depth-sdxl-1.0-small\"\n",
    "\n",
    "controlnet_pose = ControlNetModel.from_pretrained(\n",
    "    controlnet_pose_model, torch_dtype=dtype\n",
    ").to(device)\n",
    "controlnet_canny = ControlNetModel.from_pretrained(\n",
    "    controlnet_canny_model, torch_dtype=dtype\n",
    ").to(device)\n",
    "controlnet_depth = ControlNetModel.from_pretrained(\n",
    "    controlnet_depth_model, torch_dtype=dtype\n",
    ").to(device)\n",
    "\n",
    "controlnet_map = {\n",
    "    \"pose\": controlnet_pose,\n",
    "    \"canny\": controlnet_canny,\n",
    "    \"depth\": controlnet_depth,\n",
    "}\n",
    "controlnet_map_fn = {\n",
    "    \"pose\": openpose,\n",
    "    \"canny\": get_canny_image,\n",
    "    \"depth\": get_depth_map,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4992357a-2b1f-41e3-a237-17ed02049970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/workspace/InstantID/gradio_cached_examples': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r /workspace/InstantID/gradio_cached_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f201b3b-28cb-48ae-8bd2-6540b705e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(pretrained_model_name_or_path=\"wangqixun/YamerMIX_v8\", enable_lcm_arg=False):\n",
    "    if pretrained_model_name_or_path.endswith(\n",
    "        \".ckpt\"\n",
    "    ) or pretrained_model_name_or_path.endswith(\".safetensors\"):\n",
    "        scheduler_kwargs = hf_hub_download(\n",
    "            repo_id=\"wangqixun/YamerMIX_v8\",\n",
    "            subfolder=\"scheduler\",\n",
    "            filename=\"scheduler_config.json\",\n",
    "        )\n",
    "\n",
    "        (tokenizers, text_encoders, unet, _, vae) = load_models_xl(\n",
    "            pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "            scheduler_name=None,\n",
    "            weight_dtype=dtype,\n",
    "        )\n",
    "\n",
    "        scheduler = diffusers.EulerDiscreteScheduler.from_config(scheduler_kwargs)\n",
    "        pipe = StableDiffusionXLInstantIDPipeline(\n",
    "            vae=vae,\n",
    "            text_encoder=text_encoders[0],\n",
    "            text_encoder_2=text_encoders[1],\n",
    "            tokenizer=tokenizers[0],\n",
    "            tokenizer_2=tokenizers[1],\n",
    "            unet=unet,\n",
    "            scheduler=scheduler,\n",
    "            controlnet=[controlnet_identitynet],\n",
    "        ).to(device)\n",
    "\n",
    "    else:\n",
    "        pipe = StableDiffusionXLInstantIDPipeline.from_pretrained(\n",
    "            pretrained_model_name_or_path,\n",
    "            controlnet=[controlnet_identitynet],\n",
    "            torch_dtype=dtype,\n",
    "            safety_checker=None,\n",
    "            feature_extractor=None,\n",
    "        ).to(device)\n",
    "\n",
    "        pipe.scheduler = diffusers.EulerDiscreteScheduler.from_config(\n",
    "            pipe.scheduler.config\n",
    "        )\n",
    "\n",
    "    pipe.load_ip_adapter_instantid(face_adapter)\n",
    "    # load and disable LCM\n",
    "    pipe.load_lora_weights(\"latent-consistency/lcm-lora-sdxl\")\n",
    "    pipe.disable_lora()\n",
    "\n",
    "    def toggle_lcm_ui(value):\n",
    "        if value:\n",
    "            return (\n",
    "                gr.update(minimum=0, maximum=100, step=1, value=5),\n",
    "                gr.update(minimum=0.1, maximum=20.0, step=0.1, value=1.5),\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                gr.update(minimum=5, maximum=100, step=1, value=30),\n",
    "                gr.update(minimum=0.1, maximum=20.0, step=0.1, value=5),\n",
    "            )\n",
    "\n",
    "    def randomize_seed_fn(seed: int, randomize_seed: bool) -> int:\n",
    "        if randomize_seed:\n",
    "            seed = random.randint(0, MAX_SEED)\n",
    "        return seed\n",
    "\n",
    "    def remove_tips():\n",
    "        return gr.update(visible=False)\n",
    "\n",
    "    def get_example():\n",
    "        case = [\n",
    "            [\n",
    "                \"./examples/yann.jpg\",\n",
    "                \"./examples/poses/pose1.jpg\",\n",
    "                \"a man\",\n",
    "                \"Neon\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/Tom.png\",\n",
    "                \"./examples/poses/pose2.jpg\",\n",
    "                \"a man flying in the sky in Mars\",\n",
    "                \"Jungle\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/Scott.png\",\n",
    "                \"./examples/poses/pose3.jpg\",\n",
    "                \"a man doing a silly pose wearing a suite\",\n",
    "                \"Neon Noir\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/Paul.jpeg\",\n",
    "                \"./examples/poses/pose4.jpg\",\n",
    "                \"a man sit on a chair\",\n",
    "                \"Vibrant Color\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/kevin.png\",\n",
    "                \"./examples/poses/pose5.png\",\n",
    "                \"a man doing a silly pose wearing a suite\",\n",
    "                \"GTA\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/001.png\",\n",
    "                \"./examples/poses/pose6.png\",\n",
    "                \"a man doing a silly pose wearing a suite\",\n",
    "                \"Street Fighter\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/002.png\",\n",
    "                \"./examples/poses/pose7.jpg\",\n",
    "                \"a woman sit on a chair\",\n",
    "                \"Disco\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "            [\n",
    "                \"./examples/003.png\",\n",
    "                \"./examples/poses/pose8.png\",\n",
    "                \"a man\",\n",
    "                \"Dreamscape\",\n",
    "                \"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "            ],\n",
    "        ]\n",
    "        return case\n",
    "\n",
    "    def run_for_examples(face_file, pose_file, prompt, style, negative_prompt):\n",
    "        return generate_image(\n",
    "            face_file,\n",
    "            pose_file,\n",
    "            prompt,\n",
    "            negative_prompt,\n",
    "            style,\n",
    "            20,  # num_steps\n",
    "            0.8,  # identitynet_strength_ratio\n",
    "            0.8,  # adapter_strength_ratio\n",
    "            0.4,  # pose_strength\n",
    "            0.3,  # canny_strength\n",
    "            0.5,  # depth_strength\n",
    "            [\"pose\", \"canny\"],  # controlnet_selection\n",
    "            5.0,  # guidance_scale\n",
    "            42,  # seed\n",
    "            \"EulerDiscreteScheduler\",  # scheduler\n",
    "            False,  # enable_LCM\n",
    "            True,  # enable_Face_Region\n",
    "        )\n",
    "\n",
    "    def convert_from_cv2_to_image(img: np.ndarray) -> Image:\n",
    "        return Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    def convert_from_image_to_cv2(img: Image) -> np.ndarray:\n",
    "        return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    def draw_kps(\n",
    "        image_pil,\n",
    "        kps,\n",
    "        color_list=[\n",
    "            (255, 0, 0),\n",
    "            (0, 255, 0),\n",
    "            (0, 0, 255),\n",
    "            (255, 255, 0),\n",
    "            (255, 0, 255),\n",
    "        ],\n",
    "    ):\n",
    "        stickwidth = 4\n",
    "        limbSeq = np.array([[0, 2], [1, 2], [3, 2], [4, 2]])\n",
    "        kps = np.array(kps)\n",
    "\n",
    "        w, h = image_pil.size\n",
    "        out_img = np.zeros([h, w, 3])\n",
    "\n",
    "        for i in range(len(limbSeq)):\n",
    "            index = limbSeq[i]\n",
    "            color = color_list[index[0]]\n",
    "\n",
    "            x = kps[index][:, 0]\n",
    "            y = kps[index][:, 1]\n",
    "            length = ((x[0] - x[1]) ** 2 + (y[0] - y[1]) ** 2) ** 0.5\n",
    "            angle = math.degrees(math.atan2(y[0] - y[1], x[0] - x[1]))\n",
    "            polygon = cv2.ellipse2Poly(\n",
    "                (int(np.mean(x)), int(np.mean(y))),\n",
    "                (int(length / 2), stickwidth),\n",
    "                int(angle),\n",
    "                0,\n",
    "                360,\n",
    "                1,\n",
    "            )\n",
    "            out_img = cv2.fillConvexPoly(out_img.copy(), polygon, color)\n",
    "        out_img = (out_img * 0.6).astype(np.uint8)\n",
    "\n",
    "        for idx_kp, kp in enumerate(kps):\n",
    "            color = color_list[idx_kp]\n",
    "            x, y = kp\n",
    "            out_img = cv2.circle(out_img.copy(), (int(x), int(y)), 10, color, -1)\n",
    "\n",
    "        out_img_pil = Image.fromarray(out_img.astype(np.uint8))\n",
    "        return out_img_pil\n",
    "\n",
    "    def resize_img(\n",
    "        input_image,\n",
    "        max_side=1280,\n",
    "        min_side=1024,\n",
    "        size=None,\n",
    "        pad_to_max_side=False,\n",
    "        mode=PIL.Image.BILINEAR,\n",
    "        base_pixel_number=64,\n",
    "    ):\n",
    "        w, h = input_image.size\n",
    "        if size is not None:\n",
    "            w_resize_new, h_resize_new = size\n",
    "        else:\n",
    "            ratio = min_side / min(h, w)\n",
    "            w, h = round(ratio * w), round(ratio * h)\n",
    "            ratio = max_side / max(h, w)\n",
    "            input_image = input_image.resize([round(ratio * w), round(ratio * h)], mode)\n",
    "            w_resize_new = (round(ratio * w) // base_pixel_number) * base_pixel_number\n",
    "            h_resize_new = (round(ratio * h) // base_pixel_number) * base_pixel_number\n",
    "        input_image = input_image.resize([w_resize_new, h_resize_new], mode)\n",
    "\n",
    "        if pad_to_max_side:\n",
    "            res = np.ones([max_side, max_side, 3], dtype=np.uint8) * 255\n",
    "            offset_x = (max_side - w_resize_new) // 2\n",
    "            offset_y = (max_side - h_resize_new) // 2\n",
    "            res[\n",
    "                offset_y : offset_y + h_resize_new, offset_x : offset_x + w_resize_new\n",
    "            ] = np.array(input_image)\n",
    "            input_image = Image.fromarray(res)\n",
    "        return input_image\n",
    "\n",
    "    def apply_style(\n",
    "        style_name: str, positive: str, negative: str = \"\"\n",
    "    ) -> Tuple[str, str]:\n",
    "        p, n = styles.get(style_name, styles[DEFAULT_STYLE_NAME])\n",
    "        return p.replace(\"{prompt}\", positive), n + \" \" + negative\n",
    "\n",
    "    def generate_image(\n",
    "        face_image_path,\n",
    "        pose_image_path,\n",
    "        prompt,\n",
    "        negative_prompt,\n",
    "        style_name,\n",
    "        num_steps,\n",
    "        identitynet_strength_ratio,\n",
    "        adapter_strength_ratio,\n",
    "        pose_strength,\n",
    "        canny_strength,\n",
    "        depth_strength,\n",
    "        controlnet_selection,\n",
    "        guidance_scale,\n",
    "        seed,\n",
    "        scheduler,\n",
    "        enable_LCM,\n",
    "        enhance_face_region,\n",
    "        progress=gr.Progress(track_tqdm=True),\n",
    "    ):\n",
    "\n",
    "        if enable_LCM:\n",
    "            pipe.scheduler = diffusers.LCMScheduler.from_config(pipe.scheduler.config)\n",
    "            pipe.enable_lora()\n",
    "        else:\n",
    "            pipe.disable_lora()\n",
    "            scheduler_class_name = scheduler.split(\"-\")[0]\n",
    "\n",
    "            add_kwargs = {}\n",
    "            if len(scheduler.split(\"-\")) > 1:\n",
    "                add_kwargs[\"use_karras_sigmas\"] = True\n",
    "            if len(scheduler.split(\"-\")) > 2:\n",
    "                add_kwargs[\"algorithm_type\"] = \"sde-dpmsolver++\"\n",
    "            scheduler = getattr(diffusers, scheduler_class_name)\n",
    "            pipe.scheduler = scheduler.from_config(pipe.scheduler.config, **add_kwargs)\n",
    "\n",
    "        if face_image_path is None:\n",
    "            raise gr.Error(\n",
    "                f\"Cannot find any input face image! Please upload the face image\"\n",
    "            )\n",
    "\n",
    "        if prompt is None:\n",
    "            prompt = \"a person\"\n",
    "\n",
    "        # apply the style template\n",
    "        prompt, negative_prompt = apply_style(style_name, prompt, negative_prompt)\n",
    "\n",
    "        face_image = load_image(face_image_path)\n",
    "        face_image = resize_img(face_image, max_side=1024)\n",
    "        face_image_cv2 = convert_from_image_to_cv2(face_image)\n",
    "        height, width, _ = face_image_cv2.shape\n",
    "\n",
    "        # Extract face features\n",
    "        face_info = app.get(face_image_cv2)\n",
    "\n",
    "        if len(face_info) == 0:\n",
    "            raise gr.Error(\n",
    "                f\"Unable to detect a face in the image. Please upload a different photo with a clear face.\"\n",
    "            )\n",
    "\n",
    "        face_info = sorted(\n",
    "            face_info,\n",
    "            key=lambda x: (x[\"bbox\"][2] - x[\"bbox\"][0]) * x[\"bbox\"][3] - x[\"bbox\"][1],\n",
    "        )[\n",
    "            -1\n",
    "        ]  # only use the maximum face\n",
    "        face_emb = face_info[\"embedding\"]\n",
    "        face_kps = draw_kps(convert_from_cv2_to_image(face_image_cv2), face_info[\"kps\"])\n",
    "        img_controlnet = face_image\n",
    "        if pose_image_path is not None:\n",
    "            pose_image = load_image(pose_image_path)\n",
    "            pose_image = resize_img(pose_image, max_side=1024)\n",
    "            img_controlnet = pose_image\n",
    "            pose_image_cv2 = convert_from_image_to_cv2(pose_image)\n",
    "\n",
    "            face_info = app.get(pose_image_cv2)\n",
    "\n",
    "            if len(face_info) == 0:\n",
    "                raise gr.Error(\n",
    "                    f\"Cannot find any face in the reference image! Please upload another person image\"\n",
    "                )\n",
    "\n",
    "            face_info = face_info[-1]\n",
    "            face_kps = draw_kps(pose_image, face_info[\"kps\"])\n",
    "\n",
    "            width, height = face_kps.size\n",
    "\n",
    "        if enhance_face_region:\n",
    "            control_mask = np.zeros([height, width, 3])\n",
    "            x1, y1, x2, y2 = face_info[\"bbox\"]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "            control_mask[y1:y2, x1:x2] = 255\n",
    "            control_mask = Image.fromarray(control_mask.astype(np.uint8))\n",
    "        else:\n",
    "            control_mask = None\n",
    "\n",
    "        if len(controlnet_selection) > 0:\n",
    "            controlnet_scales = {\n",
    "                \"pose\": pose_strength,\n",
    "                \"canny\": canny_strength,\n",
    "                \"depth\": depth_strength,\n",
    "            }\n",
    "            pipe.controlnet = MultiControlNetModel(\n",
    "                [controlnet_identitynet]\n",
    "                + [controlnet_map[s] for s in controlnet_selection]\n",
    "            )\n",
    "            control_scales = [float(identitynet_strength_ratio)] + [\n",
    "                controlnet_scales[s] for s in controlnet_selection\n",
    "            ]\n",
    "            control_images = [face_kps] + [\n",
    "                controlnet_map_fn[s](img_controlnet).resize((width, height))\n",
    "                for s in controlnet_selection\n",
    "            ]\n",
    "        else:\n",
    "            pipe.controlnet = controlnet_identitynet\n",
    "            control_scales = float(identitynet_strength_ratio)\n",
    "            control_images = face_kps\n",
    "\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        print(\"Start inference...\")\n",
    "        print(f\"[Debug] Prompt: {prompt}, \\n[Debug] Neg Prompt: {negative_prompt}\")\n",
    "\n",
    "        pipe.set_ip_adapter_scale(adapter_strength_ratio)\n",
    "        images = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            image_embeds=face_emb,\n",
    "            image=control_images,\n",
    "            control_mask=control_mask,\n",
    "            controlnet_conditioning_scale=control_scales,\n",
    "            num_inference_steps=num_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            generator=generator,\n",
    "        ).images\n",
    "\n",
    "        return images[0], gr.update(visible=True)\n",
    "\n",
    "    # Description\n",
    "    title = r\"\"\"\n",
    "    <h1 align=\"center\">InstantID: Zero-shot Identity-Preserving Generation in Seconds</h1>\n",
    "    \"\"\"\n",
    "\n",
    "    description = r\"\"\"\n",
    "    <b>Official 🤗 Gradio demo</b> for <a href='https://github.com/InstantID/InstantID' target='_blank'><b>InstantID: Zero-shot Identity-Preserving Generation in Seconds</b></a>.<br>\n",
    "\n",
    "    How to use:<br>\n",
    "    1. Upload an image with a face. For images with multiple faces, we will only detect the largest face. Ensure the face is not too small and is clearly visible without significant obstructions or blurring.\n",
    "    2. (Optional) You can upload another image as a reference for the face pose. If you don't, we will use the first detected face image to extract facial landmarks. If you use a cropped face at step 1, it is recommended to upload it to define a new face pose.\n",
    "    3. (Optional) You can select multiple ControlNet models to control the generation process. The default is to use the IdentityNet only. The ControlNet models include pose skeleton, canny, and depth. You can adjust the strength of each ControlNet model to control the generation process.\n",
    "    4. Enter a text prompt, as done in normal text-to-image models.\n",
    "    5. Click the <b>Submit</b> button to begin customization.\n",
    "    6. Share your customized photo with your friends and enjoy! 😊\"\"\"\n",
    "\n",
    "    article = r\"\"\"\n",
    "    ---\n",
    "    📝 **Citation**\n",
    "    <br>\n",
    "    If our work is helpful for your research or applications, please cite us via:\n",
    "    ```bibtex\n",
    "    @article{wang2024instantid,\n",
    "    title={InstantID: Zero-shot Identity-Preserving Generation in Seconds},\n",
    "    author={Wang, Qixun and Bai, Xu and Wang, Haofan and Qin, Zekui and Chen, Anthony},\n",
    "    journal={arXiv preprint arXiv:2401.07519},\n",
    "    year={2024}\n",
    "    }\n",
    "    ```\n",
    "    📧 **Contact**\n",
    "    <br>\n",
    "    If you have any questions, please feel free to open an issue or directly reach us out at <b>haofanwang.ai@gmail.com</b>.\n",
    "    \"\"\"\n",
    "\n",
    "    tips = r\"\"\"\n",
    "    ### Usage tips of InstantID\n",
    "    1. If you're not satisfied with the similarity, try increasing the weight of \"IdentityNet Strength\" and \"Adapter Strength.\"    \n",
    "    2. If you feel that the saturation is too high, first decrease the Adapter strength. If it remains too high, then decrease the IdentityNet strength.\n",
    "    3. If you find that text control is not as expected, decrease Adapter strength.\n",
    "    4. If you find that realistic style is not good enough, go for our Github repo and use a more realistic base model.\n",
    "    \"\"\"\n",
    "\n",
    "    css = \"\"\"\n",
    "    .gradio-container {width: 85% !important}\n",
    "    \"\"\"\n",
    "    with gr.Blocks(css=css) as demo:\n",
    "        # description\n",
    "        gr.Markdown(title)\n",
    "        gr.Markdown(description)\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                with gr.Row(equal_height=True):\n",
    "                    # upload face image\n",
    "                    face_file = gr.Image(\n",
    "                        label=\"Upload a photo of your face\", type=\"filepath\"\n",
    "                    )\n",
    "                    # optional: upload a reference pose image\n",
    "                    pose_file = gr.Image(\n",
    "                        label=\"Upload a reference pose image (Optional)\",\n",
    "                        type=\"filepath\",\n",
    "                    )\n",
    "\n",
    "                # prompt\n",
    "                prompt = gr.Textbox(\n",
    "                    label=\"Prompt\",\n",
    "                    info=\"Give simple prompt is enough to achieve good face fidelity\",\n",
    "                    placeholder=\"A photo of a person\",\n",
    "                    value=\"\",\n",
    "                )\n",
    "\n",
    "                submit = gr.Button(\"Submit\", variant=\"primary\")\n",
    "                enable_LCM = gr.Checkbox(\n",
    "                    label=\"Enable Fast Inference with LCM\", value=enable_lcm_arg,\n",
    "                    info=\"LCM speeds up the inference step, the trade-off is the quality of the generated image. It performs better with portrait face images rather than distant faces\",\n",
    "                )\n",
    "                style = gr.Dropdown(\n",
    "                    label=\"Style template\",\n",
    "                    choices=STYLE_NAMES,\n",
    "                    value=DEFAULT_STYLE_NAME,\n",
    "                )\n",
    "\n",
    "                # strength\n",
    "                identitynet_strength_ratio = gr.Slider(\n",
    "                    label=\"IdentityNet strength (for fidelity)\",\n",
    "                    minimum=0,\n",
    "                    maximum=1.5,\n",
    "                    step=0.05,\n",
    "                    value=0.80,\n",
    "                )\n",
    "                adapter_strength_ratio = gr.Slider(\n",
    "                    label=\"Image adapter strength (for detail)\",\n",
    "                    minimum=0,\n",
    "                    maximum=1.5,\n",
    "                    step=0.05,\n",
    "                    value=0.80,\n",
    "                )\n",
    "                with gr.Accordion(\"Controlnet\"):\n",
    "                    controlnet_selection = gr.CheckboxGroup(\n",
    "                        [\"pose\", \"canny\", \"depth\"], label=\"Controlnet\", value=[\"pose\"],\n",
    "                        info=\"Use pose for skeleton inference, canny for edge detection, and depth for depth map estimation. You can try all three to control the generation process\"\n",
    "                    )\n",
    "                    pose_strength = gr.Slider(\n",
    "                        label=\"Pose strength\",\n",
    "                        minimum=0,\n",
    "                        maximum=1.5,\n",
    "                        step=0.05,\n",
    "                        value=0.40,\n",
    "                    )\n",
    "                    canny_strength = gr.Slider(\n",
    "                        label=\"Canny strength\",\n",
    "                        minimum=0,\n",
    "                        maximum=1.5,\n",
    "                        step=0.05,\n",
    "                        value=0.40,\n",
    "                    )\n",
    "                    depth_strength = gr.Slider(\n",
    "                        label=\"Depth strength\",\n",
    "                        minimum=0,\n",
    "                        maximum=1.5,\n",
    "                        step=0.05,\n",
    "                        value=0.40,\n",
    "                    )\n",
    "                with gr.Accordion(open=False, label=\"Advanced Options\"):\n",
    "                    negative_prompt = gr.Textbox(\n",
    "                        label=\"Negative Prompt\",\n",
    "                        placeholder=\"low quality\",\n",
    "                        value=\"(lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\",\n",
    "                    )\n",
    "                    num_steps = gr.Slider(\n",
    "                        label=\"Number of sample steps\",\n",
    "                        minimum=1,\n",
    "                        maximum=100,\n",
    "                        step=1,\n",
    "                        value=5 if enable_lcm_arg else 30,\n",
    "                    )\n",
    "                    guidance_scale = gr.Slider(\n",
    "                        label=\"Guidance scale\",\n",
    "                        minimum=0.1,\n",
    "                        maximum=20.0,\n",
    "                        step=0.1,\n",
    "                        value=0.0 if enable_lcm_arg else 5.0,\n",
    "                    )\n",
    "                    seed = gr.Slider(\n",
    "                        label=\"Seed\",\n",
    "                        minimum=0,\n",
    "                        maximum=MAX_SEED,\n",
    "                        step=1,\n",
    "                        value=42,\n",
    "                    )\n",
    "                    schedulers = [\n",
    "                        \"DEISMultistepScheduler\",\n",
    "                        \"HeunDiscreteScheduler\",\n",
    "                        \"EulerDiscreteScheduler\",\n",
    "                        \"DPMSolverMultistepScheduler\",\n",
    "                        \"DPMSolverMultistepScheduler-Karras\",\n",
    "                        \"DPMSolverMultistepScheduler-Karras-SDE\",\n",
    "                    ]\n",
    "                    scheduler = gr.Dropdown(\n",
    "                        label=\"Schedulers\",\n",
    "                        choices=schedulers,\n",
    "                        value=\"EulerDiscreteScheduler\",\n",
    "                    )\n",
    "                    randomize_seed = gr.Checkbox(label=\"Randomize seed\", value=True)\n",
    "                    enhance_face_region = gr.Checkbox(label=\"Enhance non-face region\", value=True)\n",
    "\n",
    "            with gr.Column(scale=1):\n",
    "                gallery = gr.Image(label=\"Generated Images\")\n",
    "                usage_tips = gr.Markdown(\n",
    "                    label=\"InstantID Usage Tips\", value=tips, visible=False\n",
    "                )\n",
    "\n",
    "            submit.click(\n",
    "                fn=remove_tips,\n",
    "                outputs=usage_tips,\n",
    "            ).then(\n",
    "                fn=randomize_seed_fn,\n",
    "                inputs=[seed, randomize_seed],\n",
    "                outputs=seed,\n",
    "                queue=False,\n",
    "                api_name=False,\n",
    "            ).then(\n",
    "                fn=generate_image,\n",
    "                inputs=[\n",
    "                    face_file,\n",
    "                    pose_file,\n",
    "                    prompt,\n",
    "                    negative_prompt,\n",
    "                    style,\n",
    "                    num_steps,\n",
    "                    identitynet_strength_ratio,\n",
    "                    adapter_strength_ratio,\n",
    "                    pose_strength,\n",
    "                    canny_strength,\n",
    "                    depth_strength,\n",
    "                    controlnet_selection,\n",
    "                    guidance_scale,\n",
    "                    seed,\n",
    "                    scheduler,\n",
    "                    enable_LCM,\n",
    "                    enhance_face_region,\n",
    "                ],\n",
    "                outputs=[gallery, usage_tips],\n",
    "            )\n",
    "\n",
    "            enable_LCM.input(\n",
    "                fn=toggle_lcm_ui,\n",
    "                inputs=[enable_LCM],\n",
    "                outputs=[num_steps, guidance_scale],\n",
    "                queue=False,\n",
    "            )\n",
    "\n",
    "        gr.Examples(\n",
    "            examples=get_example(),\n",
    "            inputs=[face_file, pose_file, prompt, style, negative_prompt],\n",
    "            fn=run_for_examples,\n",
    "            outputs=[gallery, usage_tips],\n",
    "            cache_examples=True,\n",
    "        )\n",
    "\n",
    "        gr.Markdown(article)\n",
    "\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e50082d1-161b-4000-85a1-112e1bd718a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:01<00:00,  4.53steps/s]\n",
      "/tmp/ipykernel_150/3199718478.py:206: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  mode=PIL.Image.BILINEAR,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: '/workspace/InstantID/gradio_cached_examples/75'\n",
      "Caching example 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, a man, emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e7bd110ad0458cbe06efb5cd71d8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 2/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: waist-up \"a man flying in the sky in Mars in a Jungle\" by Syd Mead, tangerine cold color palette, muted colors, detailed, 8k,photo r3al,dripping paint,3d toon style,3d style,Movie Still, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87588d94524452bbd5e9da4559f19ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man doing a silly pose wearing a suite . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229eda2f12c941f09bfe7a3c631ac301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 4/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, a man sit on a chair, highly detailed, sharp focus, the clouds,colorful,ultra sharpness, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401a5758df1448bbadc0feb6b37d2375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: GTA-style artwork a man doing a silly pose wearing a suite . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed, \n",
      "[Debug] Neg Prompt: realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb2b6c6354f4d4d9be4a0df9ccc1b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 6/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Street Fighter style a man doing a silly pose wearing a suite . Vibrant, dynamic, arcade, 2D fighting game, highly detailed, reminiscent of Street Fighter series, \n",
      "[Debug] Neg Prompt: 3D, realistic, modern, photorealistic, turn-based strategy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366ce1998b074d40b53ac498e9a194aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 7/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Disco-themed a woman sit on a chair . Vibrant, groovy, retro 70s style, shiny disco balls, neon lights, dance floor, highly detailed, \n",
      "[Debug] Neg Prompt: minimalist, rustic, monochrome, contemporary, simplistic (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7faffe2cd29e43c0882f84454084f085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching example 8/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Dreamscape a man . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed, \n",
      "[Debug] Neg Prompt: realistic, concrete, ordinary, mundane (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca55f0ac604454b8c85674e6e651f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://95e68130fa42b86a8e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://95e68130fa42b86a8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (270 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: GTA-style artwork a man stood by the window of his house, gazing out at the breathtaking scene before him. The mountains in the distance towered majestically, their peaks touching the sky, while the clear, sparkling water flowed gently in the river below, reflecting the sunlight in a dazzling display. All around, the green spaces stretched far and wide, a vibrant tapestry of life and color that seemed to pulse with energy. The lush grass swayed softly in the breeze, dotted with wildflowers of every hue, creating a scene so peaceful it could calm any troubled heart. Nearby, a winding road snaked its way through the landscape, a thin ribbon of gray amidst the overwhelming green, leading to places unseen and adventures untold. From his vantage point, he could see the world in all its natural glory, a picturesque view that filled him with a sense of wonder and tranquility. The beauty of the scene was a stark contrast to the battles and struggles he knew too well, offering a moment of respite and reflection. As he stood there, lost in the beauty of the world outside his window, he felt a deep connection to the land, a reminder of the simple joys and serene moments that life could offer amidst the chaos of existence. . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed, \n",
      "[Debug] Neg Prompt: realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecb0c24e6a94ada9c2445510ddf0b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: GTA-style artwork a man stood by the window of his house, gazing out at the breathtaking scene before him. The mountains in the distance towered majestically, their peaks touching the sky, while the clear, sparkling water flowed gently in the river below, reflecting the sunlight in a dazzling display. All around, the green spaces stretched far and wide, a vibrant tapestry of life and color that seemed to pulse with energy. The lush grass swayed softly in the breeze, dotted with wildflowers of every hue, creating a scene so peaceful it could calm any troubled heart. Nearby, a winding road snaked its way through the landscape, a thin ribbon of gray amidst the overwhelming green, leading to places unseen and adventures untold. From his vantage point, he could see the world in all its natural glory, a picturesque view that filled him with a sense of wonder and tranquility. The beauty of the scene was a stark contrast to the battles and struggles he knew too well, offering a moment of respite and reflection. As he stood there, lost in the beauty of the world outside his window, he felt a deep connection to the land, a reminder of the simple joys and serene moments that life could offer amidst the chaos of existence. . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed, \n",
      "[Debug] Neg Prompt: realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c67f13f1f8424f9d67f0ab149e0eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: GTA-style artwork a man stood by the window of his house, gazing out at the breathtaking scene before him. The mountains in the distance towered majestically, their peaks touching the sky, while the clear, sparkling water flowed gently in the river below, reflecting the sunlight in a dazzling display. All around, the green spaces stretched far and wide, a vibrant tapestry of life and color that seemed to pulse with energy. The lush grass swayed softly in the breeze, dotted with wildflowers of every hue, creating a scene so peaceful it could calm any troubled heart. Nearby, a winding road snaked its way through the landscape, a thin ribbon of gray amidst the overwhelming green, leading to places unseen and adventures untold. From his vantage point, he could see the world in all its natural glory, a picturesque view that filled him with a sense of wonder and tranquility. The beauty of the scene was a stark contrast to the battles and struggles he knew too well, offering a moment of respite and reflection. As he stood there, lost in the beauty of the world outside his window, he felt a deep connection to the land, a reminder of the simple joys and serene moments that life could offer amidst the chaos of existence. . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed, \n",
      "[Debug] Neg Prompt: realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42873c284d424cf8b3afab258cb6a2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: GTA-style artwork a man stood by the window of his house, gazing out at the breathtaking scene before him. The mountains in the distance towered majestically, their peaks touching the sky, while the clear, sparkling water flowed gently in the river below, reflecting the sunlight in a dazzling display. All around, the green spaces stretched far and wide, a vibrant tapestry of life and color that seemed to pulse with energy. The lush grass swayed softly in the breeze, dotted with wildflowers of every hue, creating a scene so peaceful it could calm any troubled heart. Nearby, a winding road snaked its way through the landscape, a thin ribbon of gray amidst the overwhelming green, leading to places unseen and adventures untold. From his vantage point, he could see the world in all its natural glory, a picturesque view that filled him with a sense of wonder and tranquility. The beauty of the scene was a stark contrast to the battles and struggles he knew too well, offering a moment of respite and reflection. As he stood there, lost in the beauty of the world outside his window, he felt a deep connection to the land, a reminder of the simple joys and serene moments that life could offer amidst the chaos of existence. . Satirical, exaggerated, pop art style, vibrant colors, iconic characters, action-packed, \n",
      "[Debug] Neg Prompt: realistic, black and white, low contrast, impressionist, cubist, noisy, blurry, deformed (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f1c26eb812487aa808bf6295247235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035722ea07944903ba8d91c5a6962bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42d727110d4451da6eb2292a6a10a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy., emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e98c9b4d0b14584b4ca0c56e0d4cea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy., emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f094ef3fdafc45c6b3385ed372c7d7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy., emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f47dcc7cd2b84f438af238042c58a0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: masterpiece painting, buildings in the backdrop, kaleidoscope, lilac orange blue cream fuchsia bright vivid gradient colors, the scene is cinematic, a man was at the beach, his feet in the warm sand, a big smile on his face. He was flying a colorful kite, watching it dance in the blue sky above the sparkling sea. The sun was shining, and a gentle breeze made the heat bearable. Kids were building sandcastles nearby, and the sound of waves crashing softly added to the perfect day. he felt light and carefree, laughing as he tugged on the kite string, making the kite swoop and soar. For that moment, everything was just right, and he was truly happy., emotional realism, double exposure, watercolor ink pencil, graded wash, color layering, magic realism, figurative painting, intricate motifs, organic tracery, polished, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d0c55dd98f418bb9bbf6c013da6da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d65e6c09ae04b58964d787e438bab9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dba561976d145b28c06e60957a4ef30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6573d2d46af649819f7d386f450672cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6e217fbaf54e2e867d11cad7ad9c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6486683be51461da3ffb7da1e1f869a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47477ac3fa22449bb0bef283e3c9daa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec2e2c9d768495dbe776caa4a6f1b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Neon noir a man sat at a cozy café table, a warm cup of coffee in hand, laughing with a friend seated across from him. The table was littered with the remnants of their afternoon treat—crumbs from a shared pastry and two almost empty coffee cups. Sunlight filtered through the café windows, casting a soft glow on their faces, highlighting Achilles’ contented smile. The air around them buzzed with the quiet hum of other patrons chatting, but their focus was solely on each other, engrossed in a conversation that flowed as smoothly as the coffee they sipped, a picture of ease and friendship. . Cyberpunk, dark, rainy streets, neon signs, high contrast, low light, vibrant, highly detailed, \n",
      "[Debug] Neg Prompt: bright, sunny, daytime, low contrast, black and white, sketch, watercolor (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd01b32102144d7b7206218ee6066b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, a man stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with he at its center, a figure consumed by his own wrath, unmoving yet turbulent., highly detailed, sharp focus, the clouds,colorful,ultra sharpness, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d2ff5b0e7d44379c2517e4f63cbf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: vibrant colorful, ink sketch|vector|2d colors, at nightfall, sharp focus, a man stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with he at its center, a figure consumed by his own wrath, unmoving yet turbulent., highly detailed, sharp focus, the clouds,colorful,ultra sharpness, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09e5295c235a4113860a1d8ce5bb91fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Street Fighter style a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Vibrant, dynamic, arcade, 2D fighting game, highly detailed, reminiscent of Street Fighter series, \n",
      "[Debug] Neg Prompt: 3D, realistic, modern, photorealistic, turn-based strategy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71e143962afc4365b7264b52a619abd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Street Fighter style a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Vibrant, dynamic, arcade, 2D fighting game, highly detailed, reminiscent of Street Fighter series, \n",
      "[Debug] Neg Prompt: 3D, realistic, modern, photorealistic, turn-based strategy (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, gree\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa456eb799024504bc0f307d56560a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Dreamscape a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed, \n",
      "[Debug] Neg Prompt: realistic, concrete, ordinary, mundane (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36db02db70754b9d9bb391accd04e795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Dreamscape a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed, \n",
      "[Debug] Neg Prompt: realistic, concrete, ordinary, mundane (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63e8cc1205c44299f450304bb248829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Dreamscape a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed, \n",
      "[Debug] Neg Prompt: realistic, concrete, ordinary, mundane (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05382cf140c4902bcb59ac1a234b5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start inference...\n",
      "[Debug] Prompt: Dreamscape a woman stood in the middle of a cluttered room, his fists clenched at his sides, anger etched across his face. Broken pieces of a vase lay scattered at his feet, a testament to his fury. The walls, once bright, seemed to darken with his mood. A single chair was overturned, its position speaking volumes of the chaos within him. The air was thick, charged with tension, as if waiting for a storm to break. Despite the silence, the scene screamed of conflict, with she at its center, a figure consumed by his own wrath, unmoving yet turbulent. . Surreal, ethereal, dreamy, mysterious, fantasy, highly detailed, \n",
      "[Debug] Neg Prompt: realistic, concrete, ordinary, mundane (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6527d89b984e49519f00b6f2015a2b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?steps/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model_name_or_path = \"wangqixun/YamerMIX_v8\"\n",
    "enable_LCM = False\n",
    "\n",
    "main(pretrained_model_name_or_path, enable_LCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfddafb-8003-4199-93a0-d9657abb8bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9212bdeb-6e95-47e5-92fe-234be8878765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da56c7ee-0738-411d-9880-252c5386a596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0bff1-978d-4450-b6f3-8b4db67ab562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469cc582-357d-4e17-aaa7-50e727d7993b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870b183-c8fc-41ff-91a8-c45c1056921f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f92618d-c3f5-4009-adf5-ed07c1921110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n",
      "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:01<00:00,  4.70it/s]\n",
      "/workspace/InstantID/gradio_demo/app.py:188: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  pad_to_max_side=False, mode=PIL.Image.BILINEAR, base_pixel_number=64):\n",
      "Caching examples at: '/workspace/InstantID/gradio_cached_examples/26'\n",
      "Caching example 1/5\n",
      "/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
      "Start inference...\n",
      "[Debug] Prompt: cinema 4d render, a man, high contrast, vibrant and saturated, sico style, surrounded by magical glow,floating ice shards, snow crystals, cold, windy background, frozen natural landscape in background  cinematic atmosphere,highly detailed, sharp focus, intricate design, 3d, unreal engine, octane render, CG best quality, highres, photorealistic, dramatic lighting, artstation, concept art, cinematic, epic Steven Spielberg movie still, sharp focus, smoke, sparks, art by pascal blanche and greg rutkowski and repin, trending on artstation, hyperrealism painting, matte painting, 4k resolution, \n",
      "[Debug] Neg Prompt: (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green (lowres, low quality, worst quality:1.2), (text:1.2), watermark, (frame:1.2), deformed, ugly, deformed eyes, blur, out of focus, blurry, deformed cat, deformed, photo, anthropomorphic cat, monochrome, photo, pet collar, gun, weapon, blue, 3d, drones, drone, buildings in background, green\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (126 > 77). Running this sequence through the model will result in indexing errors\n",
      "  0%|                                                 | 0/30 [00:02<?, ?steps/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/InstantID/gradio_demo/app.py\", line 453, in <module>\n",
      "    main(args.pretrained_model_name_or_path, args.enable_LCM)\n",
      "  File \"/workspace/InstantID/gradio_demo/app.py\", line 433, in main\n",
      "    gr.Examples(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/helpers.py\", line 75, in create_examples\n",
      "    examples_obj.create()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/helpers.py\", line 301, in create\n",
      "    client_utils.synchronize_async(self.cache)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio_client/utils.py\", line 808, in synchronize_async\n",
      "    return fsspec.asyn.sync(fsspec.asyn.get_loop(), func, *args, **kwargs)  # type: ignore\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py\", line 103, in sync\n",
      "    raise return_result\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/fsspec/asyn.py\", line 56, in _runner\n",
      "    result[0] = await coro\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/helpers.py\", line 362, in cache\n",
      "    prediction = await Context.root_block.process_api(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 2106, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 833, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 695, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/workspace/InstantID/gradio_demo/app.py\", line 151, in run_for_examples\n",
      "    return generate_image(face_file, None, prompt, negative_prompt, style, 30, 0.8, 0.8, 5, 42, False, True)\n",
      "  File \"/workspace/InstantID/gradio_demo/app.py\", line 276, in generate_image\n",
      "    images = pipe(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/workspace/InstantID/./pipeline_stable_diffusion_xl_instantid_full.py\", line 1143, in __call__\n",
      "    noise_pred = self.unet(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_condition.py\", line 1112, in forward\n",
      "    sample, res_samples = downsample_block(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/unet_2d_blocks.py\", line 1160, in forward\n",
      "    hidden_states = attn(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/transformer_2d.py\", line 392, in forward\n",
      "    hidden_states = block(\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention.py\", line 393, in forward\n",
      "    ff_output = self.ff(norm_hidden_states, scale=lora_scale)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/attention.py\", line 665, in forward\n",
      "    hidden_states = module(hidden_states, scale)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/models/activations.py\", line 103, in forward\n",
      "    return hidden_states * self.gelu(gate)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 23.50 GiB total capacity; 10.67 GiB already allocated; 53.31 MiB free; 10.94 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python gradio_demo/app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cb398be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_5m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_5m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_11m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_11m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_224 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_384 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "/usr/local/lib/python3.10/dist-packages/controlnet_aux/segment_anything/modeling/tiny_vit_sam.py:654: UserWarning: Overwriting tiny_vit_21m_512 in registry with controlnet_aux.segment_anything.modeling.tiny_vit_sam.tiny_vit_21m_512. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  return register_model(fn_wrapper)\n",
      "config.json: 100%|█████████████████████████| 9.88k/9.88k [00:00<00:00, 44.0MB/s]\n",
      "pytorch_model.bin: 100%|██████████████████████| 490M/490M [00:02<00:00, 233MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "preprocessor_config.json: 100%|████████████████| 382/382 [00:00<00:00, 2.32MB/s]\n",
      "body_pose_model.pth: 100%|████████████████████| 209M/209M [00:00<00:00, 224MB/s]\n",
      "hand_pose_model.pth: 100%|████████████████████| 147M/147M [00:00<00:00, 233MB/s]\n",
      "facenet.pth: 100%|████████████████████████████| 154M/154M [00:00<00:00, 233MB/s]\n",
      "/usr/local/lib/python3.10/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/glintr100.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: ./models/antelopev2/scrfd_10g_bnkps.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "set det-size: (640, 640)\n",
      "config.json: 100%|█████████████████████████| 1.24k/1.24k [00:00<00:00, 7.85MB/s]\n",
      "diffusion_pytorch_model.bin: 100%|██████████| 5.00G/5.00G [00:24<00:00, 203MB/s]\n",
      "config.json: 100%|█████████████████████████| 1.31k/1.31k [00:00<00:00, 6.07MB/s]\n",
      "diffusion_pytorch_model.safetensors: 100%|██| 5.00G/5.00G [00:22<00:00, 219MB/s]\n",
      "config.json: 100%|█████████████████████████| 1.26k/1.26k [00:00<00:00, 7.69MB/s]\n",
      "diffusion_pytorch_model.safetensors: 100%|███| 640M/640M [00:15<00:00, 41.1MB/s]\n",
      "The config attributes {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False} were passed to StableDiffusionXLInstantIDPipeline, but are not expected and will be ignored. Please verify your model_index.json configuration file.\n",
      "Keyword arguments {'controlnet_list': ['controlnet', 'RPMultiControlNetModel'], 'requires_aesthetics_score': False, 'safety_checker': None} are not expected by StableDiffusionXLInstantIDPipeline and will be ignored.\n",
      "Loading pipeline components...: 100%|█████████████| 7/7 [00:03<00:00,  2.16it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/InstantID/gradio_demo/app-multicontrolnet.py\", line 675, in <module>\n",
      "    main(args.pretrained_model_name_or_path, args.enable_LCM)\n",
      "  File \"/workspace/InstantID/gradio_demo/app-multicontrolnet.py\", line 120, in main\n",
      "    ).to(device)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_utils.py\", line 869, in to\n",
      "    module.to(device, dtype)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1145, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 797, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 6 more times]\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 820, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1143, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 23.50 GiB total capacity; 10.67 GiB already allocated; 19.31 MiB free; 11.00 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "# !python gradio_demo/app.py\n",
    "!python gradio_demo/app-multicontrolnet.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deef9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
